{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./venv/lib/python3.5/site-packages\r\n",
      "Requirement already satisfied: numpy in ./venv/lib/python3.5/site-packages (from torch)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "num_entries= 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now create 5000 databases with 1 person missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well from 1..5000\n",
    "# copy db and remove an entry at a given place \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_and_parallels(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    catalog = []\n",
    "    for i in range(0,num_entries):\n",
    "        tmp = torch.cat([db[0:i], db[i+1:]])\n",
    "        catalog.append(tmp)\n",
    "    return db , catalog\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(db, parallels) = create_db_and_parallels(5000)\n",
    "len(parallels)\n",
    "\n",
    "len(parallels[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirically evaluate the sensitivity of a function to the removal of 1 of the db records\n",
    "# the simplest query we can have is a simple sum \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full db result tensor(2491)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sum_entries(db):\n",
    "    return db.sum()\n",
    "    \n",
    "# what is the value of this function on the original db\n",
    "full_db_result = sum_entries(db)\n",
    "print (\"full db result\", full_db_result)\n",
    "\n",
    "sensitivity = 0\n",
    "    \n",
    "for p in parallels: \n",
    "    distance = torch.abs(sum_entries(p)-full_db_result)\n",
    "    if(distance > sensitivity):\n",
    "        sensitivity = distance\n",
    "        \n",
    "sensitivity    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empirically measuring sensitivity\n",
    "def sensitivity(query, num_entries=1000):\n",
    "    (db, parallels) = create_db_and_parallels(num_entries)\n",
    "    sensitivity = 0\n",
    "    full_db_result = query(db)\n",
    "    print (\"full db result\",full_db_result)\n",
    "    for p in parallels: \n",
    "        distance = torch.abs(query(p)- full_db_result)\n",
    "        \n",
    "        if(distance > sensitivity):\n",
    "            sensitivity = distance\n",
    "        \n",
    "    return sensitivity  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full db result tensor(2513)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = sum_entries\n",
    "    \n",
    "sensitivity(sum_entries,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full db result tensor(0.4902)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.0001)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def query(db):\n",
    "    return db.float().mean()\n",
    "    \n",
    "sensitivity(query,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full db result tensor(1.) tensor([0, 0, 1, 1, 1, 1, 0, 0, 1, 1], dtype=torch.uint8)\n",
      "distance tensor(0.)\n",
      "distance tensor(0.)\n",
      "distance tensor(1.)\n",
      "distance tensor(1.)\n",
      "distance tensor(1.)\n",
      "distance tensor(1.)\n",
      "distance tensor(0.)\n",
      "distance tensor(0.)\n",
      "distance tensor(1.)\n",
      "distance tensor(1.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# computes sum over database and returns whether that sum is less (or more)\n",
    "# than a certain threshold\n",
    "def is_greater_than_threshold(db,t=5):\n",
    "    return (db.sum() > t).float()\n",
    "\n",
    "# create 10 databases\n",
    "def sensitivity_for_each(query, num_entries=10):\n",
    "    (db, parallels) = create_db_and_parallels(num_entries)\n",
    "    sensitivity = 0\n",
    "    full_db_result = query(db)\n",
    "    \n",
    "    print (\"full db result\",full_db_result,db)\n",
    "    \n",
    "    for p in parallels: \n",
    "        distance = torch.abs(query(p)- full_db_result)\n",
    "        print (\"distance\", distance)\n",
    "\n",
    "        if(distance > sensitivity):\n",
    "            sensitivity = distance\n",
    "    return sensitivity  \n",
    "\n",
    "\n",
    "sensitivity_for_each(is_greater_than_threshold,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform an attack on row 10, can we know of value of row if we remove it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "(db, parallels) = create_db_and_parallels(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove index 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb = torch.cat([db[0:9], db[10:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdb[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0, dtype=torch.uint8)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db[10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1, dtype=torch.uint8)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#differencing attack using addition\n",
    "sum(db)- sum(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0043)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#differencing attack using mean > 0 means row is a \"1\" as we just have ones and zeros\n",
    "sum(db).float()/len(db) - sum(pdb).float()/len(pdb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create db and a copy of it for which every entry has been flipped according to plausible deniability\n",
    "# if ramndom(0,1) == 1 leave entry\n",
    "# else if random(0,1) == 1 set entry to 1\n",
    "#       else set entry to 0\n",
    "\n",
    "# so 50% of values of original db are left alone, 50% are randomly flipped\n",
    "import random\n",
    "\n",
    "def create_augmented_db(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    # now create copy \n",
    "    augmented_database = db.clone();\n",
    "    for i in range(0,num_entries):\n",
    "        flip_1 = random.randint(0,1)\n",
    "        flip_2 = random.randint(0,1)\n",
    "        if (flip_1 == 0):\n",
    "            augmented_database[i] = flip_2\n",
    "            \n",
    "    # returns original db and teh augmented one\n",
    "    return (db, augmented_database)\n",
    "\n",
    "\n",
    "(db, augmented_db) = create_augmented_db(100)\n",
    "\n",
    "def create_augmented_db(num_entries):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    # now create copy \n",
    "    augmented_database = db.clone();\n",
    "    for i in range(0,num_entries):\n",
    "        flip_1 = random.randint(0,1)\n",
    "        flip_2 = random.randint(0,1)\n",
    "        # if 1st coin flip is a 1 nothing happens, things flow as usual\n",
    "        # if 1st coing flip is a zero we change the result of the entry \n",
    "        # to the result of the 2nd coin flip\n",
    "        if (flip_1 == 0):\n",
    "            augmented_database[i] = flip_2\n",
    "            \n",
    "    # returns original db and teh augmented one\n",
    "    return (db, augmented_database)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# the noise parameter changes how likely it is for the 1st coin flip to be a 1 versus a zero\n",
    "# a percentage\n",
    "def create_augmented_db_with_variable_noise(num_entries, noise):\n",
    "    db = torch.rand(num_entries) > 0.5\n",
    "    # now create copy \n",
    "    augmented_database = db.clone();\n",
    "    \n",
    "    for i in range(0,num_entries):\n",
    "        flip_1 = 0\n",
    "        # if noise 0.5 we are on the 'even' case in which 0 and 1 are equally likely\n",
    "        if (random.uniform(0,1) > noise):\n",
    "            flip_1 = 1\n",
    "        \n",
    "        flip_2 = random.randint(0,1)\n",
    "        # if 1st coin flip is a 1 nothing happens, things flow as usual\n",
    "        # if 1st coing flip is a zero we change the result of the entry \n",
    "        # to the result of the 2nd coin flip\n",
    "        if (flip_1 == 0):\n",
    "            augmented_database[i] = flip_2\n",
    "            \n",
    "    # returns original db and teh augmented one\n",
    "    return (db, augmented_database)\n",
    "\n",
    "\n",
    "# LOCAL DIFFERENTIAL PRIVACY, ADING NOISE TO INDIVIDUAL DATA POINTS\n",
    "\n",
    "def query(num_entries, noise = 0.5):\n",
    "    (db, augmented_db) = create_augmented_db_with_variable_noise(num_entries, noise)\n",
    "    true_result = torch.mean(db.float())\n",
    "    \n",
    "    #augmented result\n",
    "    ag_result = torch.mean(augmented_db.float())\n",
    "    # the augmented result is the result of averaging real result with 0.5\n",
    "    # output of our query on ag_resul is skewed but that is not what we were after\n",
    "    # we need to de-skew ag_result\n",
    "    estimated_result = ag_result/noise -((1-noise)*0.5/noise)\n",
    "    print (\"true result  and estimated result \", true_result, estimated_result)\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true result  and estimated result  tensor(0.4972) tensor(0.4997)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query(100000,0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the more datapoints that we have the more the noise will tend to diffuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49, dtype=torch.uint8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# laplacian mechanism to perform 2 kinds of queries\n",
    "# sum and mean \n",
    "epsilon = 0.5\n",
    "\n",
    "# remember, this removes an entry at a given place\n",
    "(db, parallels) = create_db_and_parallels(100)\n",
    "\n",
    "sum(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4900)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_query(db):\n",
    "    return db.sum()\n",
    "\n",
    "#adding laplacian noise \n",
    "# we know in our dB (of 0s and 1s sensitivity of sum is 1)\n",
    "def laplacian_mechanism(db, query, sensitivity):\n",
    "    beta = sensitivity/epsilon\n",
    "    noise = torch.tensor(np.random.laplace(0,beta,1))\n",
    "    return query(db) + noise\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([46.8743], dtype=torch.float64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mechanism(db,sum_query,1 )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_query(db):\n",
    "    return torch.mean(db.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4900)"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_query(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7010.2391], dtype=torch.float64)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sensitivity of sum is 1\n",
    "laplacian_mechanism(db, sum_query,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-21.0346], dtype=torch.float64)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# assuming sensitivity of mean is 1/100 (if db size is 100)\n",
    "laplacian_mechanism(db,mean_query,1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower values of epsilon will add TOO MUCH noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon =0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6343], dtype=torch.float64)"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laplacian_mechanism(db,mean_query,1/100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
